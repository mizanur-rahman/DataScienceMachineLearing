{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <h1> Santander Customer Transaction Prediction </h1></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Competition Description </h5> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Santander our mission is to help people and businesses prosper. We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals.\n",
    "\n",
    "Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?\n",
    "\n",
    "In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Let's get started </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir ('D:\\Jupyter')\n",
    "# To plot Pretty figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Modelling\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import pickle\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize= 15)\n",
    "mpl.rc('xtick', labelsize= 12)\n",
    "mpl.rc('ytick', labelsize= 12)\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "# avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Jupyter'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv (r'D:\\Desktop\\Kaggle Competitions\\santander-customer-transaction-prediction\\train.csv')\n",
    "test = pd.read_csv (r'D:\\Desktop\\Kaggle Competitions\\santander-customer-transaction-prediction\\test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv (r'D:\\Desktop\\Kaggle Competitions\\santander-customer-transaction-prediction/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>var_199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>var_61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>var_71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>var_70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>var_69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Total  Percent\n",
       "var_199      0      0.0\n",
       "var_61       0      0.0\n",
       "var_71       0      0.0\n",
       "var_70       0      0.0\n",
       "var_69       0      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first check the missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent*100], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing value in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exploratory Data Analysis (EDA) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
       "       'var_5', 'var_6', 'var_7',\n",
       "       ...\n",
       "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
       "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
       "      dtype='object', length=202)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the name of the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info() method is useful to get a quick description of the data, in\n",
    "particular the total number of rows, each attribute’s type, and the number\n",
    "of nonnull values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> The target variable</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze our target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d400d42f88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use seaborn\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='target',data=train,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% of the target has value of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Prepare the Data for Machine Learning Algorithms </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thw following models are updated from these beutiful Kaggle karnels\n",
    "https://www.kaggle.com/bogorodvo/starter-code-saving-and-loading-lgb-xgb-cb\n",
    "https://www.kaggle.com/jesucristo/30-lines-starter-solution-fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Different Models </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> LGBMClassifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name):\n",
    "    \n",
    "    model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                               n_estimators=500,\n",
    "                               learning_rate=0.02,\n",
    "                               colsample_bytree=0.3,\n",
    "                               num_leaves=2,\n",
    "                               metric='auc',\n",
    "                               objective='binary', \n",
    "                               n_jobs=-1)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=0, \n",
    "              early_stopping_rounds=100)\n",
    "                  \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save LightGBM Model\n",
    "    save_to = '{}{}_fold{}.txt'.format(lgb_path, name, counter+1)\n",
    "    model.booster_.save_model(save_to)\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> XGBClassifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name):\n",
    "    \n",
    "    model = xgb.XGBClassifier(max_depth=2,\n",
    "                              n_estimators=500,\n",
    "                              colsample_bytree=0.3,\n",
    "                              learning_rate=0.02,\n",
    "                              objective='binary:logistic', \n",
    "                              n_jobs=-1)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=0, \n",
    "              early_stopping_rounds=100)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save XGBoost Model\n",
    "    save_to = '{}{}_fold{}.dat'.format(xgb_path, name, counter+1)\n",
    "    pickle.dump(model, open(save_to, \"wb\"))\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> CatBoostClassifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cb(X_fit, y_fit, X_val, y_val, counter, cb_path, name):\n",
    "    \n",
    "    model = cb.CatBoostClassifier(iterations=500,\n",
    "                                  max_depth=2,\n",
    "                                  learning_rate=0.02,\n",
    "                                  colsample_bylevel=0.03,\n",
    "                                  objective=\"Logloss\")\n",
    "                                  \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=0, early_stopping_rounds=100)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save Catboost Model          \n",
    "    save_to = \"{}{}_fold{}.mlmodel\".format(cb_path, name, counter+1)\n",
    "    model.save_model(save_to, format=\"coreml\", \n",
    "                     export_parameters={'prediction_type': 'probability'})\n",
    "                     \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Training the Data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage( lgb_path, xgb_path, cb_path):\n",
    "    \n",
    "    print('Load Train Data.')\n",
    "    df = train\n",
    "    print('\\nShape of Train Data: {}'.format(df.shape))\n",
    "    \n",
    "    y_df = np.array(df['target'])                        \n",
    "    df_ids = np.array(df.index)                     \n",
    "    df.drop(['ID_code', 'target'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_cv_result = np.zeros(df.shape[0])\n",
    "    xgb_cv_result = np.zeros(df.shape[0])\n",
    "    cb_cv_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    skf.get_n_splits(df_ids, y_df)\n",
    "    \n",
    "    print('\\nModel Fitting...')\n",
    "    for counter, ids in enumerate(skf.split(df_ids, y_df)):\n",
    "        print('\\nFold {}'.format(counter+1))\n",
    "        X_fit, y_fit = df.values[ids[0]], y_df[ids[0]]\n",
    "        X_val, y_val = df.values[ids[1]], y_df[ids[1]]\n",
    "    \n",
    "        print('LigthGBM')\n",
    "        lgb_cv_result[ids[1]] += fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name='lgb')\n",
    "        print('XGBoost')\n",
    "        xgb_cv_result[ids[1]] += fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name='xgb')\n",
    "        print('CatBoost')\n",
    "        cb_cv_result[ids[1]]  += fit_cb(X_fit,  y_fit, X_val, y_val, counter, cb_path,  name='cb')\n",
    "        \n",
    "        del X_fit, X_val, y_fit, y_val\n",
    "        gc.collect()\n",
    "    \n",
    "    auc_lgb  = round(roc_auc_score(y_df, lgb_cv_result),4)\n",
    "    auc_xgb  = round(roc_auc_score(y_df, xgb_cv_result),4)\n",
    "    auc_cb   = round(roc_auc_score(y_df, cb_cv_result), 4)\n",
    "    auc_mean = round(roc_auc_score(y_df, (lgb_cv_result+xgb_cv_result+cb_cv_result)/3), 4)\n",
    "    auc_mean_lgb_cb = round(roc_auc_score(y_df, (lgb_cv_result+cb_cv_result)/2), 4)\n",
    "    print('\\nLightGBM VAL AUC: {}'.format(auc_lgb))\n",
    "    print('XGBoost  VAL AUC: {}'.format(auc_xgb))\n",
    "    print('Catboost VAL AUC: {}'.format(auc_cb))\n",
    "    print('Mean Catboost+LightGBM VAL AUC: {}'.format(auc_mean_lgb_cb))\n",
    "    print('Mean XGBoost+Catboost+LightGBM, VAL AUC: {}\\n'.format(auc_mean))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h5> Predictction </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stage.\n",
      "\n",
      "Load Train Data.\n",
      "\n",
      "Shape of Train Data: (200000, 202)\n",
      "\n",
      "Model Fitting...\n",
      "\n",
      "Fold 1\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "Fold 2\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "Fold 3\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "LightGBM VAL AUC: 0.7901\n",
      "XGBoost  VAL AUC: 0.55\n",
      "Catboost VAL AUC: 0.837\n",
      "Mean Catboost+LightGBM VAL AUC: 0.8191\n",
      "Mean XGBoost+Catboost+LightGBM, VAL AUC: 0.819\n",
      "\n",
      "Prediction Stage.\n",
      "\n",
      "Load Test Data.\n",
      "\n",
      "Shape of Test Data: (200000, 201)\n",
      "\n",
      "Make predictions...\n",
      "\n",
      "With LightGBM...\n",
      "With XGBoost...\n",
      "With CatBoost...\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def prediction_stage( lgb_path, xgb_path, cb_path):\n",
    "    \n",
    "    print('Load Test Data.')\n",
    "    df = test\n",
    "    print('\\nShape of Test Data: {}'.format(df.shape))\n",
    "    \n",
    "    df.drop(['ID_code'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_models = sorted(os.listdir(lgb_path))\n",
    "    xgb_models = sorted(os.listdir(xgb_path))\n",
    "    cb_models  = sorted(os.listdir(cb_path))\n",
    "    \n",
    "    lgb_result = np.zeros(df.shape[0])\n",
    "    xgb_result = np.zeros(df.shape[0])\n",
    "    cb_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    print('\\nMake predictions...\\n')\n",
    "    \n",
    "    print('With LightGBM...')\n",
    "    for m_name in lgb_models:\n",
    "        #Load LightGBM Model\n",
    "        model = lgb.Booster(model_file='{}{}'.format(lgb_path, m_name))\n",
    "        lgb_result += model.predict(df.values)\n",
    "     \n",
    "    print('With XGBoost...')    \n",
    "    for m_name in xgb_models:\n",
    "        #Load Catboost Model\n",
    "        model = pickle.load(open('{}{}'.format(xgb_path, m_name), \"rb\"))\n",
    "        xgb_result += model.predict_proba(df.values)[:,1]\n",
    "    \n",
    "    print('With CatBoost...')        \n",
    "    for m_name in cb_models:\n",
    "        #Load Catboost Model\n",
    "        model = cb.CatBoostClassifier()\n",
    "        model = model.load_model('{}{}'.format(cb_path, m_name), format = 'coreml')\n",
    "        cb_result += model.predict(df.values, prediction_type='Probability')[:,1]\n",
    "    \n",
    "    lgb_result /= len(lgb_models)\n",
    "    xgb_result /= len(xgb_models)\n",
    "    cb_result  /= len(cb_models)\n",
    "    \n",
    "\n",
    "    submission['target'] = (lgb_result+xgb_result+cb_result)/3\n",
    "    submission.to_csv('xgb_lgb_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = (lgb_result+cb_result)/2\n",
    "    submission.to_csv('lgb_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = xgb_result\n",
    "    submission.to_csv('xgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = lgb_result\n",
    "    submission.to_csv('lgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = cb_result\n",
    "    submission.to_csv('cb_starter_submission.csv', index=False)\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "#     train_path = '../input/train.csv'\n",
    "#     test_path  = '../input/test.csv'\n",
    "    \n",
    "    lgb_path = './lgb_models_stack/'\n",
    "    xgb_path = './xgb_models_stack/'\n",
    "    cb_path  = './cb_models_stack/'\n",
    "\n",
    "    #Create dir for models\n",
    "    os.mkdir(lgb_path)\n",
    "    os.mkdir(xgb_path)\n",
    "    os.mkdir(cb_path)\n",
    "\n",
    "    print('Train Stage.\\n')\n",
    "    train_stage(lgb_path='./lgb_models_stack/', xgb_path='./xgb_models_stack/', cb_path='./cb_models_stack/')\n",
    "    \n",
    "    print('Prediction Stage.\\n')\n",
    "    prediction_stage(lgb_path, xgb_path, cb_path)\n",
    "    \n",
    "    print('\\nDone.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better accuracy is obtained using only few lines of code with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv (r'D:\\Desktop\\Kaggle Competitions\\santander-customer-transaction-prediction\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= [x for x in train.columns if x not in ['ID_code', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.900408\tvalid_1's auc: 0.881818\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.900367\tvalid_1's auc: 0.885342\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.901211\tvalid_1's auc: 0.874796\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.899707\tvalid_1's auc: 0.888583\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.900525\tvalid_1's auc: 0.877114\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.899914\tvalid_1's auc: 0.884917\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.899731\tvalid_1's auc: 0.886042\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.899755\tvalid_1's auc: 0.890776\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.900216\tvalid_1's auc: 0.881486\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.900015\tvalid_1's auc: 0.887894\n",
      "Fold 10\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\ttraining's auc: 0.900017\tvalid_1's auc: 0.890331\n",
      "Fold 11\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\ttraining's auc: 0.900581\tvalid_1's auc: 0.884248\n",
      "CV score: 0.88442 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ID_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0f4bc41f2d42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CV score: {:<8.5f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"ID_code\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID_code\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ID_code'"
     ]
    }
   ],
   "source": [
    "target = train['target']\n",
    "param = {\n",
    "    'bagging_freq': 5,          \n",
    "    'bagging_fraction': 0.38,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             'feature_fraction': 0.04,     'learning_rate': 0.0085,\n",
    "    'max_depth': -1,             'metric':'auc',                'min_data_in_leaf': 80,     'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,            'num_threads': 8,              'tree_learner': 'serial',   'objective': 'binary',\n",
    "    'reg_alpha': 0.1302650970728192, 'reg_lambda': 0.3603427518866501,'verbosity': 1\n",
    "}\n",
    "folds = StratifiedKFold(n_splits=12, shuffle=False, random_state=99999)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 1000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 2000)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
